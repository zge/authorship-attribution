In this video, I'm going to explain how
adding noise can help systems escape from
local minima.
And, I'm going to show what you have to do
to the units in Hopfield net to add noise
in the appropriate way.
I'm not going to introduce the idea that
we confined better minima by using noise.
So, Hopfield net always makes decisions
that reduce the energy, or if it doesn't
state of the unit, the energy stays the
same.
This makes it impossible to climb out of a
local minimum.
So, if you look at the landscape here.
If we get into the local minimum A,
there's no way we're going to get over the
energy barrier to get to the better
minimum B because we can't go uphill in
energy.
If we add random noise, we can escape from
poor minima, especially minima that is
shallow, that is, ones that don't have big
energy barriers around them.
It turns out, rather than using a fixed
noise level, the most effective strategy
is to start with a lot of noise which
allows you to explore the space on a
coarse scale and find the generally good
regions of the space, and then to decrease
the noise level.
With a lot of noise, you can cross big
barriers.
As you decrease the noise level, you start
concentrating on the best nearby minima.
If you slowly reduce the noise, so the
system ends up in a deep minimum, that's
called simulated annealing.
And this ideal was, propogated by
Kirkpatrick at around the same time as
Hopfield nets were proposed.
So, the reason for simulated annealing is
because the temperature, in a physical
system, or in a simulated system with a
energy function,
Affects the transition probabilities.
So, in a high temperature system, the
probability of going uphill from B to A is
lower than the probability of going
downhill from A to B.
But it's not much lower.
In effect, the temperature flattens the
energy landscape, and so the little black
dots are meant to be particles.
And what we are imagining is particles
moving about according to the transition
probabilities that you get with an energy
function and a temperature.
And this might be a typical distribution
if you're on the system of high
temperature where it's easier to cross
barriers, but it's also hard to stay in a
deep minimum once you've got that.
If you are in the system of much lower
temperature,
Then your probability of crossing barriers
gets much smaller but your ratio gets much
better.
So, the ratio of the probability of going
from A to B versus the probability of
going from B to A is much better in the
low temperature system.
And so, if we run it long enough, we would
expect all of the particles to end up in
B.
But if we just run it for a long time at
low temperature, it will take a very long
time for particles to escape from A.
And it turns out a good compromise is to
start at a high temperature and gradually
reduce the temperature.
The way we get noise in to Hopfield net is
to replace the binary threshold units by
binary stochastic units and make biased
random decisions.
And the amount of noise is controlled by
something called temperature,
Which you'll see in a minute in the
equation.
Raising the noise level is equivalent to
decreasing all the energy gaps between
configurations.
So, this is our normal logistic equation.
But with the energy gap scaled by a
temperature.
If the temperature is very high, that
exponent will be roughly zero, so the
right hand side will be one over one plus
one. And so, the probability of the unit
turning on will be about a half.
It'll be in it's on and off states, more
or less equally off.
As we lower the temperature,
Depending on the sign of delta E, the unit
will become either more and more firmly on
and more and more firmly off.
At zero temperature, which is what we're
be using in a Hopfield net,
Then the sign of delta E determines
whether the right hand side goes to zero
or goes to one.
But, with T zero, it will either be zero
or one on the right hand side.
And so, the unit will behave
deterministically and that's a binary
threshold unit.
It will always adopt whatever of the two
states is the lowest energy.
So, the energy gap we saw on a previous
slide, and it's just the difference in the
energy of the whole system depending on
whether unit I is off, or the unit I is
on.
Although simulated annealing is a very
powerful method for improving searches
that get stuck in local optima, and
although it was influential in leading
Terry Sejnowski and I to the ideas behind
Boltzmann machines, it's actually a big
distraction from understanding Boltzmann
machines.
So, I'm not going to talk about it anymore
in this course even though it's a very
interesting idea.
And, from now on, I'm going to use binary
stochastic units that have a temperature
of one.
That is, it's the standard logistic
function in the energy gap.
So, one concept that you need to
understand in order to understand the
learning procedure for both the machines,
is the concept of thermal equilibrium.
And because we're setting the temperature
to one, this the concept of thermal
equilibrium at a fix temperature.
It's a difficult concept. Most people
think that it means the system is settled
down and isn't changing anymore. That's
normally what equilibrium means. But it's
not the states of the individual units
that are settled down.
The individual units are still rattling
around at thermal equilibrium, and less
temperature zero. The thing that settles
down is the probability distribution over
configurations. That's a difficult concept
the first time you meet it, and so I'm
going to give you an example.
The probability distribution settles to a
particular distribution called the
Stationary Distribution.
The stationary distribution is determined
by the energy function of the system.
And, in fact, in the stationary
distribution, the probability of any
configuration is proportional to each of
the minus its energy.
A nice intuitive way to think about
thermal equilibrium is to imagine a huge
ensemble of identical systems that all
have exactly the same energy function.
So, imagine a very large number of
stochastic Hopfield nets all with the same
weights.
Now, in that huge ensemble, we can define
the probability of configuration as the
fraction of the systems that are in that
configuration.
So, now we can understand what's happening
as we approach thermal equilibrium.
We can start with any distribution we like
over all these identical systems. We could
make them all, be in the same
configuration. So, that's the distribution
with a property of one on one
configuration, and zero on everything
else. Or we could start them off, with an
equal number of systems in each possible
configuration.
So that's a uniform distribution.
And then, we're going to keep applying our
stochastic update rule.
Which, in the case of a stochastic
Hopfield net would mean,
You pick a unit, and you look at its
energy gap.
And you make a random decision based on
that energy gap about whether to turn it
on or turn it off.
Then, you go and pick another unit, and so
on.
We keep applying that stochastic rule.
And after we've run systems stochastically
in this way,
We may eventually reach a situation where
the fraction of the systems in each
configuration remains constant.
In fact, that's what will happen if we
have symmetric connections.
That's the stationary distribution that
physicists call thermal equilibrium.
Any given system keeps changing its
configuration.
We apply the update rule,
And the states of its units will keep
flipping between zero and one.
But, the fraction of systems in any
particular configuration doesn't change.
And that's because we have many, many more
systems than we have configurations.
So, here's an analogy kust to help with
the concept.
Imagine a very large casino in Las Vegas
with lots of card dealers. And, in fact,
we have many more than 52 factorial card
dealers. We start with all the card packs
in the standard order that they come from
the manufacturer. Let's suppose that has
the ace of spades, and the king of spades,
and the queen of spades.
And then, the dealers all start shuffling.
And they do random shuffles, they don't do
fancy shuffles that bring them back to the
same order again.
After a few shuffles, there's still a good
chance that the king of spades will be
next to the queen of spades in any given
pack.
So, the packs have not yet forgotten where
they started.
Their initial order is still influencing
their current order.
If we keep shuffling, eventually the
initial order will be irrelevant.
The packs will have forgotten where they
started.
And, in fact, in this example, there will
be an equal number of packs in each of the
52 factorial possible orders.
Once this has happened, if we carry on
shuffling,
There'll still be an equal number of packs
in each of the 52 factorial orders.
That's why it's called equilibrium.
It's because the fraction in any one
configuration doesn't change,
Even though the individual systems are
still changing.
The thing that's wrong with this analogy
is that once we've each equilibrium here,
all configurations have equal energy.
And so, they all have the same
probability.
In general, we're interested in reaching
equilibrium for systems where some
configurations have lower energy than
others.
