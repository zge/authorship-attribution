In this video, I'm going to describe how
to make full Bayesian learning practical
for neural networks that have thousands,
and perhaps even millions of weights.
The technique that's used is a Monte Carlo
method, which seems very odd the first
time you hear about it.
We use a random number generator to move
around the space of weight vectors in a
random way,
But with a bias towards going downhill in
our cost function.
If we do this right, we get a beautiful
property, which is that we sample weight
vectors in proportion to their probability
in the posterior distribution.
And that means by sampling a lot of weight
factors, we can get a good approximation
to the full Bayesian method.
The number of grid points is exponential
in the number of parameters.
So we can't make a grid for more than a
few parameters.
This is enough data so that most of the
parameter vectors are very unlikely.
Only a tiny fraction of the group points,
will make a significant contribution to
the predictions.
So may be you can just focus on evaluating
this tiny fraction if we can find it.
An idea that makes Bayesian learning
feasible is that it might be good enough
just to sample weight vectors according to
their posterior probabilities.
So if you look at this equation, the
probability that we assigned to a test
output, given the input for the test case
and the training data, is the sum over all
points in weight space of the posterity
probability of that point in weight space
given the training data, times the
probability distribution for the test
values that we predict given that point in
weight space W I, and given the test
input.
Now instead of adding up all the terms in
that sum, we could just sample terms from
that sum.
What we do is we sample the weight vectors
in proportion to that probability.
So either we sample them or we don't.
So they'll get a weight of one or zero.
But the probability of getting a one.
That is, the probability being sampled,
will be their posterior probability.
So that will give us the correct expected
value for the right hand side.
It'll have noise due to the sampling but
it'll have the correct expected value.
So here's a picture of what happens in
standard back propagation.
On the right I've drawn the weight space.
Which of course is very high dimensional
and unbounded.
And this is a very bad picture of, but
it's the best I can do.
In this white space, I've drawn some
contours which are meant to be contours of
equal values of our cost function.
And the way back propagation is normally
used, is we start with some small value of
the weights, and then we follow the
gradient.
We move downhill in our cost function, in
the direction that increases the
log-likelihood, plus the log-prior, summed
over all training guesses.
Eventually, we'll either end up at a local
minimum or we'll get stuck on a plateau,
Or we'll just move so slowly that we run
out of patience.
But the main point of this picture, is
that we follow a path from an initial
point to some final, single point.
Now if we're using a sampling method, what
we could do, we start at the same place as
we did before, but each time we update the
weights.
We add a bit of Gaussian noise so we're
just turning around.
The weight vector will never settle down
then.
It'll keep on moving around.
It'll wander over the space, but always
preferring low cost regions.
That is, it'll tend to go downhill if it
can.
An important question is whether we can
say anything about how often the weights
will visit each point in that space.
So the red dots are meant to be samples we
took of the weights as we wandered around
the space.
And the idea is, we might save the weights
after every 10,000 steps.
And if you look at those red dots, a few
of them are in high cost regions, because
those regions are quite big.
The deepest minimum has the most red dots,
and other minima also have red dots.
The dots aren't right at the bottom of the
minima, because they're noisy samples.
If we add that Gaussian noise in just the
right way, there's a wonderful property of
Markov chain Monte Carlo.
It's an amazing fact.
The weight vectors, if we wandered around
for long enough, will be unbiased samples
from the true posterior distribution
overweight factors.
That is, those red dots we saw in the
previous slide will be sampled from the
posterior, where weight vectors are a
highly probable under the posterior, a
much more likely to be represented by a
red dot than weight factor that is highly
improbable.
This is called Markov Chain Monte Carlo,
and makes it feasible to use Bayesian
learning with thousands of parameters.
The method I suggested of adding some
Gaussian noise is called the [UNKNOW
method.
And it's not the most efficient method.
There's more sophisticated methods that
are more efficient,
And what I mean by more efficient is, they
don't need to wander around the weight
space for so long before you can start
taking those red samples.
Full Bayesian learning can actually be
done with mini batches.
When we compute the gradient of the cost
function on a random mini batch, we're
gonna get an unbiased estimate but with
sampling noise.
And the idea is to use that sampling noise
to provide the noise that the marked up
chained Monte Carlo method needs.
It's a very clever idea.
Recently, Welling and his collaborators
made it work nicely, so they could fairly
efficiently get samples from the post area
distribution over weights using mini-batch
methods.
This should make it possible to use full
Bayesian learning for much larger networks
where you have to train them with
mini-batch to have any hope of ever
finishing training them.
