In this video, I'm going to talk about
applying restrictive Boltzmann machines to
collaborative filtering.
Collaborative filtering means trying to
figure out how much a user would like one
product based on how much that user liked
other products and how much many other
users like products.
The particular case we'll look at is the
Netflix competition, in which a machine
learning algorithm has to predict how much
a particular user will like a particular
movie.
The training data for this competition
consists of 100 million ratings of 18,000
movies by half a million users.
So it's quite a big data set.
It's not the kind of thing anybody at the
time imagined a Boltzmann machine could
deal with.
As we'll see, there's an important trick
to being able to get a restricted
Boltzmann machine to cope with the fact
that nearly all the ratings of nearly all
the movies are missing.
But when we use this trick, we're able to
train models, that are very useful in
practice, and were in fact used in the
winning entry.
So now I'm going to explain how restricted
Boltzmann machines were used for
collaborative filtering in the Netflix
competition.
In that competition, you're given most of
the ratings that half a million users
gave, to 18,000 movies, and each movie
gets rated on a scale from one to five.
Each user, of course, only rates a small
fraction of the movies.
But even so, there's about a hundred
million ratings, so it's quite a big data
set.
You have to predict the ratings that the
users gave to held out movies, and if you
can do that well you get a big prize.
You actually win a million dollars if
you're the best person at doing that.
So, you can draw the ratings in a big
matrix like this where we have movies
across the top, and users down the side.
And so for example, user two gave a rating
of five to movie one, and a rating of one
to movie three.
User four gave a rating of four to movie
one, and the question is what rating did
he give to movie three.
You might decide he's quite like user two
because he rated movie one the same way.
So maybe like user two he hated movie
three.
On the other hand, user four liked movie
six.
So maybe he likes all the movies.
By the time you've done that much
reasoning, you realize you better use some
statistics.
Let's start by trying to use a language
model.
It sounds bizarre, but as you'll see it's
equivalent to a standard method.
So we can write the data as a string of
triples, much like family trees.
Each triple has a form, user, movie and
rating.
So here's some of the data on that table
on the previous slide and we just have to
predict the third term of a triple.
So if we built a language model, what we
would do is we'd convert each user into a
vector features for that user, that is a
vector that we learned and we converted
movie into a vector features for that
movie, a vector that we learned and from
those two feature vectors, we try and
predict the rating.
Now, the obvious way to do this is to put
in a big hidden layer, and make the
feature vectors feed into the hidden layer
and then have the hidden layer predict the
rating.
We tried that, and we couldn't get that to
work any better than a very simple method.
Which is simply, to take the scalar
product of the feature vector for the user
and the feature vector for the movie.
You just multiply them together point
wise, add it up and output that as your
rating.
So it's not even a soft max, you actually
output whatever real number you get form
the scaler product.
Now that's exactly equivalent to doing
something else, which is normally called a
Matrix Factorization model.
If we arrange the user features down the
rows and the movie features above the
columns, we can see that if we multiply,
that matrix of users times features by the
matrix of features times movies, then
we'll get predictions for the ratings.
And it will be exactly equivalent to the
language model that's beside it.
So the matrix factorization model is the
most commonly used model for collaborative
filtering like this, and it works pretty
well.
Now let's consider an alternative model,
using our restrictive Boltzmann.
Machine.
It's not obvious how you would apply a
restrictive Boltzmann machine to this
problem.
And so we had to do some thinking.
In the end we decided that we would treat
each user as a training case.
And so a user is really a vector of movie
ratings.
And for each movie we would have a visible
unit that had five alternative values.
So visible units instead of being binary,
are five way softmaxes.
And so the network of our restrictive
Boltzmann machine looks like this.
Each of it's visible units is a five way
softmax, with one visible unit per movie.
You might start worrying about there being
18,000 visible units here.
And then we had about 100 binary hidden
units.
And each hidden unit is connected to all
five values of the soft max.
It also has a bias.
And so you can see the number of
parameters we'll have is large.
The CD learning rule for softmax,
incidentally is exactly the same as for a
binary unit and like I said we've got
about a 100 in units.
And what we're going to do is learn a
model and then try and fill in one of the
missing values using the model.
Now the problem with this approach, is we
don't want to have an RBM with 18,000
visible units.
Only a few of which have known values.
That's a huge number of missing values to
begin with.
And there's a neat way around that.
For each user we use an RBM that only has
as many visual units as the movies that
the user rated.
So, it's possible that every user will
correspond to a different RBM, with a
different subset, with visible units.
Now, all of these RBMs are going to share
the same weights.
That is, we know which move is which.
And so if two users saw the same movie and
rated the same movie, the weights from
that movie to the hidden units will be the
same for those two users.
So we're doing an awful lot of weight
sharing here.
And that's lucky, because for each user,
We only get one training case.
We make this specific RBM for each user
with the right architecture, that is, the
right number of visible units for the
movies that the user rated.
And now there's only one training case,
which is that rating vector.
But all of these half a million training
cases share weights to hidden units.
So the learning works fine.
The models are trained with CD1 and then
after a while with CD3. That is you go up
and down three times before you collect
the statistics for the negative phase and
then we CD5 and then we CD9 and how well
does it work?
Well the RBM's work about as well as the
matrix factorization methods but they give
very different errors.
What that means is that if you average the
predictions of the RBM's with the
predictions of the matrix factorization
methods, you get a big win, and the
winning group actually used multiple
different RBM models in their average and
multiple different matrix factorization
models and I think probably other models
as well.
As far as I know their main models were
matrix factorization models and RBM
