In this video, I'm going to introduce
Hopfield Nets.
Together with back propagation, these were
one of the main reasons for the resurgence
of interest in neural networks in the
1980s.
Hopfield networks are beautifully simple
devices that can be used for storing
memories as distributed patterns of
activity.
We are now going to learn about a
different kind of model from a feet
forward neural net.
These are sometimes called energy based
models because their properties derive
from a global energy function.
So, a Hopfield net is one of the simplest
kinds of energy-based model.
It's composed of binary threshold units
with recurrent connections between them.
In general, if you have networks of
non-linear units with recurrent
connections, they're very hard to analyze.
They can behave in many different ways.
They can settle to a stable state.
They can oscillate.
They can even be chaotic which means that,
unless you know their starting state with
infinite precision, you can't predict the
state they'll be in very far into the
future.
Fortunately, John Hopfield and various
other groups, like Stephen Grossberg's
group, realized that if the connections
are symmetric, there's a global energy
function.
Each binary configuration of the whole
network has an energy.
And so what I mean by binary configuration
is, an assignment of binary values to each
neuron in the network.
So, every neuron has a particular binary
value in that configuration.
The thing that Hopfield realized is that,
if you set up the right energy function
for binary threshold decision rule, is
actually causing the network, to go down
hill in energy, and if you keep applying
that rule, it'll end up in a energy
minima.
So, everything's controlled by the energy
function. The global energy of a
configuration is the sum of a number of
local contributions, and the main
contributions have the form of the product
of one connection weight, with the binary
states of two nuerons.
So, the energy function looks like this.
Energy is bad, so low energy is good.
And that's what those minus signs are
doing in there.
If you look at the main term here, it has
a weight which is the symmetric connection
strength between two neurons.
And it has the activities of the two
connected neurons.
So, Si is a binary variable that has
values of one or zero.
Or in another kind of Hopfield net, it has
values of one or minus one.
In addition to that quadratic term that
involves the states of two units, there's
also a bias term that only involves the
state of individual units.
The quadratic energy function makes it
possible for each unit to compute locally
how changing its state will change the
global energy.
So, we first need to define the energy
gap.
The energy gap for a unit i is the
difference in the global energy of the
whole configuration depending on whether
or not i is on.
So, the energy gap can be actually defined
as the difference between the energy when
i is off and the energy when i is on.
And that difference is what is just what
is being computed by the binary threshold
decision rule.
So, if you look at the equation for the
energy and you differentiate it with a
respect to the state of the i-th unit,
it's a funny thing to do cuz it's a binary
variable. But, if you differentiate it,
you'll see you get the binary threshold
decision rule, but without the minus sign
cuz that's for going down hill in energy.
So, by following the binary threshold
decision rule, a Hopfield net will go
downhill in its global energy.
One way to find an energy minimum in a
Hopfield net is to start from a random
state and then update the units one at a
time in random order.
So, we're doing a sequential update.
And for each unit that you pick, you
compute whichever of its two states gives
the lowest global energy and you put it in
that state independent of what state it
was previously in.
That's equivalent to saying you just used
the binary threshold decision rule.
So, let's look at a little example for the
net on the right.
We'll start with a random global state.
This was a carefully selected random
state,
And that has an energy of -three, or a
goodness of three.
It's easier to think about negative
energies which are called goodnesses.
There aren't any biases here.
So to compute the goodness, you just look
at all pairs of units that are on and add
in the weight between them.
And in this configuration, there's only
one pair of units that's active.
And that has a weight of three,
So we get a goodness of three.
Now, let's start probing the units.
Let's pick a unit at random, like that
one.
And ask, what state should that be in,
given the current states of all the other
units?
So, if we look at total input to that, it
gets an input of one  -four + zero
three, plus another zero  three, so it
gets a total input of -four.
That's below zero, so we turn it off, i.e.
It stays in the off state.
And let's probe another unit.
If we look at this unit, again, it gets a
total input of one  three + -one  zero,
so it gets a total input of three, so the
binary threshold decision rule will make
it turn on.
Let's probe one more unit.
This unit's more interesting.
It's getting an input of one  two + one 
-one + zero  three + zero <i>, -one, So</i>
that's a total input of one.
So, it will now turn on.
Previously it was off.
And so, when it turns on, the global
energy changes.
We now have a global energy of -four or a
goodness of four,
And that's a local energy minimum.
If you now try probing any of the units,
you'll see that they don't want to change
their current state.
The next is settled to a minimum.
However, the minimum it settled to is not
the deepest energy minimum.
It's just one of two minima that this net
has.
The deepest energy minimum is shown on the
right here,
And it's when the other triangle of units
that support each other is on.
That has a goodness of three + three +
-one is five.
So, that's a slightly better energy
minima.
If you look at that net, you can see the
nets composed of these two triangles in
which the units mostly support each other,
although there's a bit of disagreement at
the bottom. And each of those triangles
mostly hates the other triangle via that
connection at the top.
The triangle on the left differs from the
one on the right by having a weight of
two, where the other one has a weight of
three.
So, the triangle on the right will give
you the deepest minimum.
So, if you ask, why did the decisions need
to be sequential in the Hopfield net?
The problem is that if units make
simultaneous decisions, they could each
think they were using energy but actually
the energy could go up.
With simultaneous parallel updating, we
can get oscillations which always have a
period of two.
So, here's a little network where the
units have biases of +five, and a weight
between them of -100.
So when both units are off, the next
parallel step, if we update them both at
the same time, will turn both units on
because they each think they cam improve
things by the bias term.
But, as soon as you do that, you get this
-100,
And so you've actually made things much
worse.
So then, in the next parallel step, both
units will turn off again.
If we do the updates in parallel but with
random timing.
In other words, we don't wait for one
update to communicate the state to
everybody before we consider another
update,
But we do wait for random lengths of time
between doing updates of a given unit.
Then, those random timings will often
destroy these bi-phase oscillations.
That means that the idea that the updates
have to be sequential isn't quite as bad
as it seems from a biological perspective.
Now, what Hopfield suggested was that we
could make use of this kind of energy
based model that settles to a minimum of
it's energy for storing memories.
So, we had a very influential paper in
1982 that proposed that memories could be
energy minima of a neural net with
symmetric weights.
The binary threshold decision rule can
then take partial memories, and clean them
up into full memories. So, the memory
could be corrupted by part of it being
wrong, or part of it could just be
undecided, and we can use the net, to fill
out the memory.
The idea of memories as energy minima goes
back a long way. The first example I know
of is in a book called Principles of
Literary Criticism by I.
A.
Richards, where he proposes that memories
are like a large crystal that can sit on
different faces.
Using energy minima to represent memories
gives a content erasable memory, as
Hopfield realized.
So, that you can access an item just by
knowing part of its content.
I can tell you a few properties of
something that'll set the states of some
of the neurons in the net.
And if you've put the other neurons in
random states and now go around applying
the binary threshold rule,
With a bit of luck, you'll feel like that
memory to be some stored item that you
know about.
When Hopfield nets were proposed in 1982,
that was a very interesting property.
1982 was sixteen years before Google, now
that we have Google, we regard this as
perfectly obvious.
Another property of Hopfield netsg is
biologically interesting, is their robust
against hardware damage.
You could remove a few of the units in the
netg and unlike the central processor of
your computer, everything will still work
fine.
Psychologists have a nice analogy for this
kind of memory.
It's like reconstructing a dinosaur from
just a few of its bones because you know
something about how the bones are meant to
fit together.
So, the weights in the network give you
information about how states of neurons
fit together.
And now, given the state of a few neurons,
I can fill out the whole state to recover
a whole memory.
The storage rule for memories in the
Hopfield net is very simple.
The idea is, if we use activities of one
and minus one, that we can store a binary
statement by just incrementing the weights
between any two units by the product of
their activities.
So, it's a very simple rule shown on the
right.
One nice thing about this rule, is that
you just go through the data once and
you're done. So, it really is the genuine
online rule. that's because it's not error
driven. You're not comparing what you
would have predicted with what the right
answer is, and then making small
adjustments.
The fact that it's not an error correction
rule is both it's strength and it's
weakness.
It means it can be online, but as we'll
see later, it also means it's not a very
efficient way to store things.
We can also have biases, and as usual, we
treat the biases as weights from a
permanently on unit.
If you want to use states of zero and one
for units, which is what we'll use later,
the update rule is only slightly more
complicated.
