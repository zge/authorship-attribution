In this video, I'm going to explain, how a
Boltzmann machine models a set of binary
data vectors.
I'm going to start by explaining, why we
might want to model a set of binary data
vectors, and what we could do with such a
model if we had it.
And then I'm gonna show how the
probabilities assigned to binary data
vectors are determined by the weights in a
Boltzmann machine.
Stochastic Hopfield nets with hidden
units, which we also call as Boltzmann
machines are good at modelling binary
data.
So, given a set of binary training
vectors, they can use the hidden units to
fit a model per assigns the probability to
every possible binary vector.
Per several reasons, why you might like to
be able to do that.
If, for example you had several
distributions of binary vectors, you might
like to look at a new binary vector and
decide which distribution it came from.
So, you might have different kinds of
documents, and you might represent a
document by, a number of binary features
each of which says, whether there is more
than zero occurrences of a particular word
in that document.
For different kinds of documents, you
would expect different kinds of the
different words, may be you'll see
different correlations between words And
so you could use a set of hidden units to
model the distribution for each document.
And then you could pick the most likely
document, by seeing.
And then you could assign a test document
to the appropriate class, by seeing which
class of document is most likely to have
produced that binary vector.
You could also use Boltzmann machines for
monitoring complex systems to detect
unusual behavior.
Suppose for example that you have a
nuclear power station, and all of the
dials were binary.
So you get a whole bunch of binary numbers
that tell you something about the state of
the power station.
What you'd like to do, is notice that it's
in an unusual state.
A state that's not like states you've seen
before.
And you don't want to use supervised
learning for that.
Because really you don't want to have any
examples of states that cause it to
blowup.
You'd rather be able to detect that it's
going into such a state without every
having seen such a state before.
And you could do that by building a model
of a normal state and noticing that this
state is different from the normal states.
If you have models of several different
distributions.
You can complete the posterior probability
that a particular distribution produced
the observed data by using Bayes' Theorem.
So giving the observed data, the
probability it came from Model I, under
the assumption that it came from one of
your models, is the probability that Model
I would have produced that data, divided
by the same quantity for all models.
Now I want to talk about two ways of
producing models of data in particular
binary vectors.
The most natural way to think about
generating a binary vector is to first
generate the states of some latent
variables,
And then use the latent variables to
generate the binary vector.
So in a causal model, we use two
sequential steps.
These are the latent variables, or hidden
units, and we first pick the states of the
latent variables from their prior
distributions.
Often in the causal model, these will be
independent in the prior.
So their probability of turning on, if
they were binary latent variables, would
just depend on some bias that each one of
them has.
Then, once we picked a state for those, we
would use those to generate the states of
the visible units by using weighted
connections in this model.
So this is a kind of neural network,
causal, generative model.
It's using logistic units, and it uses
biases for the hidden units and weights on
the connections between hidden and visible
units to assign a probability to every
possible visible vector.
The probability of generating a particular
vector v, is just the sum of all the
possible hidden states of the probability
of generating those hidden state times the
probability of generating v, given that
you've already generated that hidden
state.
So, that's a causal model, factor analysis
for example is a causal model using
continuous variables.
And, it's probably the most natural way to
think about generating data.
In fact, some people when they say
generated model mean, the causal model
like this.
But just a completely different kind of
model.
A Boltzmann machine is an energy based
model, and, in this kind of model, you
don't generate data causally.
It's not a causal generative model.
Instead everything is defined in terms of
the energies of joint configurations of
visible and hidden units.
There's two ways of relating the energy of
a joint configuration to its probability.
You can simply define the probability to
be the probability of a joint
configuration of the visible and hidden
variables is proportional to e to the
negative energy of that joint
configuration.
Or you can define it procedurally by
saying we are going to define the
probability as the probability finding the
network in that state after we've updating
all the stochastic binary units for enough
time so that we reached thermal
equilibrium.
The good news is that those two
definitions agree.
The energy of a joint configuration of the
visible and hidden units has five terms in
it.
So I've put the negative energy to save
having to put lots of minus signs.
And so the negative energy of the joint
configuration VH.
That's with vector V on the visible units,
and H on the hidden units,
Has bias terms where VI is the binary
state of the Ith unit in vector V.
And the bk is the bias of the kth unit, in
this case, a hidden unit.
So that's the first two terms.
Then there's the visible-visible
interactions,
And to avoid counting each of those
interactions twice, we can, just say,
we're going to count within c's, I, and j
and make sure that I's always less than j.
That'll avoid counting the interaction of
something with itself, and also avoid
counting pairs twice, and so we don't have
to put a half in front.
Then there's the visible hidden
interactions.
My WIK is a weight on a visible hidden
interaction.
And then there's the hidden to hidden
interactions.
So the way we use the energies to define
probabilities is that the probability of a
joint configuration over vnh is
proportional to e to the minus vh.
To make that an equality we need to
normalize the right hand side by all
possible configurations over the visible
and hidden and that's what the divisor
there is.
That's often called the partition
function.
That's what physicists call it.
And notice it has exponentially many
terms.
To get the probability of a configuration
of the visible units alone, we have to sum
over all possible configurations of the
hidden units.
So P of V is the sum over all possible Hs,
of each of the minus the energy you get
with that H, normalized by the partition
function.
I want to give you an example of how we
compute the probabilities of the different
visible vectors, because that'll give you
a good feel for what's involved.
It's all very well to see the equations,
but I find that I understand it much
better when I've worked through the
computation.
So let's take a network with two hidden
units and two visible units.
And we'll ignore biases, so we just got
three weights here.
To keep things simple, I'm not gonna
connect visible units to each other.
So the first thing we do is write down all
possible states of the visible units.
I need to put them in different colors,
and I'm going to write each state four
times,
Because for each state of visible units,
there's four possible states of the hidden
units that could go with it.
So that gives us sixteen possible joint
configurations.
Now, for each of those joint
configurations, we're going to compute
it's negative energy minus E.
So if you look at the first line, when all
of the units are on.
The negative energy will be +two -one,
+one is +two.
And we do this for all sixteen possible
joint configurations.
We then take the negative energies and we
exponentiate them.
And that will give us un-normalized
probabilities.
So these are the un-normalized
probabilities of the configurations.
Their probabilities are proportional to
this.
If we add all those up to 39.7 and then we
divide everything by 39.7, we get the
probabilities of joint configurations.
There they all are.
Now, if we want the probability of a
particular visible configuration, we have
to sum over all the hidden configurations
that could go with it.
And so we add up the numbers in each
block.
And now we've computed the probability of
each possible visible vector in a
Boltson's machine that has these three
weights in it.
Now let's ask how we get a sample from the
model when the network's bigger than that.
Obviously, in the network we just
computed, we can figure out the
probability of everything'cause it's
small.
But when the network's big, we can't do
these exponentially large computations.
So, if there's more than a few hidden
units, we can't actually compute that
partition function, there's too many terms
in it.
But we can use Markov Chain Monte Carlo to
get samples from the model by starting
from a random global configuration.
And then picking units at random and
dating them stochastically based on their
energy gaps.
Those energy gaps being determined by the
states of all the other units in the
network.
If we keep doing that until the Markov
chain reaches its stationary distribution,
then we have a sample from the model.
And the probability of that sample is
related to its energy by the Boltzmann
distribution, that is, the probability of
the sample is proportional to each-(the of
the minus energy. What about getting a
sample from the posterior distribution
over hidden configurations, when given a
data vector?
It turns out we're going to need that for
learning.
So the number of possible hidden
configurations is again exponential.
So again, we use Markov Chain Monte Carlo.
And it's just the same as getting a sample
from the model, except that we keep that
we keep the visible units clamped to the
data vector we're interested in.
So we only update the hidden units.
The reason we need to get samples from the
posterior distribution, given a data
vector, is we might want to know a good
explanation for the observed data.
And, we might want to base our actions on
that good explanation.
But, we also need to know that for
learning.
