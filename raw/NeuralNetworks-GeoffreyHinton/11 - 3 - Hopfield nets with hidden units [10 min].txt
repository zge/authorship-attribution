In this video, I'm going to explain a very
different way of using Hopfield's energy
function.
We add some hidden units to the network.
And what we are trying to do is make the
states of those hidden units represent an
interpretation of the perception input
that's shown on the visible units.
So, the idea is that the weights on
between units represent constraints on
good interpretations.
And by finding a low energy state, we find
a good interpretation of the input data.
Hopfield nets combine two ideals, the idea
of that you can find a local energy
minimum by using a network of
symmetrically connected binary threshold
units, and the idea that these local
energy minima might correspond to
memories.
There's a different way of using the
ability to find local minima.
Instead of using the net to store
memories, we can use it to construct
interpretations of the sensory input.
So, the idea is that we have the input
represented by some visible units.
And we can structure an interpretation of
that input in the set of hidden units.
So, the interpretation or explanation of
the input is going to be a binary
configuration over the hidden units.
The energy of the whole system will
represent the badness of that
interpretation.
So, to get good interpretations according
to our current model of the world, which
is in the energy function, we need to find
low energy states of the hidden units,
given, the input represented by the
visible units.
I want to give an example of this to make
the idea clearer, in order to give the
example, I need to go into a little bit of
detail, about what you can infer, when you
see a 2-D line in an image.
What does that tell you about the
three-dimensional world?
So, a 2-D line in an image could have been
caused by many different three-dimensional
edges in the world.
If this blue dot is your eyeball and the
red lines are two lines of sight coming
from the center of your eyeball,
Then the black line is a possible 3-D edge
that would lead to a two-dimensional line
on your retina.
Here's another 3-D edge that would lead to
exactly the same thing on your retina.
And here's another one.
And here's another one.
All of these different 3-D edges have
exactly the same appearance in the image.
That's because we've lost the information
about how far away the ends of the line
are along that line of sight.
We know the end is somewhere along the
line of sight but we don't know the depth.
So, if we assume that a straight 3-D edge
in the world is the cause of a straight
2-D line in the image, then we've lost two
degrees of freedom of that 3-D edge, its
depth at each end.
So, there is a whole family of 3-D edges
that all correspond to the same 2-D line.
You can only see one of these 3-D edges at
a time because they all get in the way of
each other.
So now, we're in a position to see a
little example of what you might be able
to do, if you can use the fact that you
can find low energy states of a network of
binary units, to help you find
interpretations of sensory input.
So, here's the example.
You imagine we see a line drawing, and we
want to interpret it as a
three-dimensional thing.
So, the data we have, let's suppose, is a
bunch of 2-D lines like the lines shown in
the picture.
And for each possible line, we will have
set aside a neuron.
Don't worry for now about the fact that,
that will require too many neurons.
So, for every possible 2-D line, we have
neuron.
In any one picture, only a few of the
possible lines will be present.
And so , we'll activate just a few of
those neurons.
So, I've shown two edges in that picture,
activating two of the neurons.
And those are neurons that represent 2-D
lines.
They're the data.
Now, what we're going to do is have a
whole bunch of 3-D line units, one for
each possible 3-D line or 3-D edge.
So, each of the 2-D line units could be
the projection of many different possible
3-D lines. We therefore need to make the
2-D line unit excite all those 3-D lines,
but we also need to make them all compete
with one another, cuz you can only see one
of them at a time. So, here's an example
where I have a stack of 3-D line units,
the green connections are excitrity
connections coming from the 2-D line unit,
all of them with equal weight, saying, if
this line unit is present, I'm going to
try and turn on all those.
But in addition, we need competition
between those so that only one of them
will turn on, and that's what the red
lines represent. And we do that for each
2-D line unit. So, I'm just showing it to
you for the 2-D line units that happen to
be active at present.
And again, don't worry about the fact that
this would need far to many units.
Now, the story is not quite complete.
We've now wired into the neural network
the information about projection that I
showed on the previous slide,
I.e.,
The neural network in those green and red
connections understands that each 2-D line
can cross upon to many 3-D edges, but only
one of them should be present at a time.
But now, we know a lot about how 3-D edges
connect.
For example, when we see two 2-D lines
connect in the image, we think it's almost
certain that they correspond to edges that
have the same depth at the point where the
lines connect.
So, let's suppose that the two 3-D edges
I've joined there correspond to having the
same depth at the point where the two 2-D
lines join.
That means they should support each other.
It doesn't have to be like that.
You could have a very funny viewpoint
where one line ends at a different depth
from the other and you just happen to be
at the viewpoint from which they coincide
on your retina.
But that's very unlikely.
So, we're going to need to use the fact
that we expect 2-D lines that coincide in
the image to correspond to 3-D edges that
agree on the depth of that point.
So, we'll put in a lot of connections like
that.
But there's an even stronger fact we can
use which is that in our manufactured
world, we expect that quite often, 3-D
edges will join in a right angle.
And so, for two particular 3-D edges that
happen to agree in depth and join at a
right angle,
We'll put in a particularly strong
connection.
And I've indicated that by a thicker green
line.
So, by putting in lots of connections like
that, we can indicate how we expect 3-D
edges to go together to form a coherent
3-D object.
And now, we have a network that contains
information about how edges go together in
the world and about how edges project to
cause lines in the image.
And so, if we give that network an image,
it should be able to come up with an
interpretation of the image.
And for the image I'm showing you, there's
two quite different interpretations.
It's called a Necker cube, and if you look
at it long enough, it will flip in depth
on you.
And this network would have two pretty
much equally deep energy minima that
correspond to those two interpretations of
the Necker cube.
Remember, this is all just a analogy so
you understand the idea of using low
energy states as interpretations of
perceptial data.
To actually build a proper model of what
happens when the Necker cube flips will be
a lot more complicated than this.
So, if we decide we're going to use low
energy states to represent good
interpretations, then we have two issues.
The first is to do with search and I'm
going to deal with that in the next video.
The search question is, how do we avoid
the hidden units getting trapped in poor
local minima of the energy function?
The poor minima represent interpretations
that are sub-optimal, given our current
model and the weights of the network.
Can we do anything better than simply
going downhill in energy from some random
starting state?
The second issue which seems even more
difficult is how do we learn the weights
on the connections between hidden units
and between visible units and hidden
units.
Is the sum simple learning algorithm for
adjusting all those weights so that we get
sensible perception interpretations?
And notice here we haven't got a
supervisor anywhere.
We're just showing it input and we would
like it to construct tons of activity in
the hidden units that represent sensible
interpretations.
This seems like a rather tall order.
