
We've seen how to represent lines and 
planes that contain the origin. 
How do we represent those that don't 
contain the origin? 
Well let's say we want to represent a 
line that does not necessarily contain 
the origin. 
Well, we start with a line that does go 
through the origin. 
Now we know that the points forming that 
line form a vector space, big V. 
We're going to translate that line by 
adding a vector c to every vector in big 
V. 
So here's the mathematical formulation of 
that. 
And we'll abbreviate that in this way, c 
+ V. 
What we get is the line through the point 
c instead of through the origin. 
Let's try the same thing for a plane. 
How do we represent a plane that does not 
contain the origin? 
We start with a plane that does contain 
the origin. 
We know that the points of such a plane 
form a vector space big V. 
We're going to translate this by adding a 
vector c to every vector in big V. 
Looks like this, and we abbreviate it C 
plus big V. 
And what we get is a plain that goes 
through c and not through the origin. 
You know, if c is a vector and big V is a 
vector space, c plus big V is called an 
affine space. 
So examples are a line, or a plain that 
doesn't necessarily go through the 
origin. 
Let's do a more concrete example. 
Take the points u1, u2, and u3. 
We want to express the plane through 
these points as u1 plus big V, where big 
V is the span of two vectors. 
Okay? 
So big V looks like that. 
Well, we define big V as span of a and b, 
where a is the second vector minus the 
first, and b is the third vector minus 
the first. 
Now, let's look at u1 plus big V. 
It's the translation of a plane so it, 
too, is a plane. 
Now span ab contains the zero vector. 
So u1 plus span ab contains u1. 
Span ab contains a, which is u2 minus u1. 
So u1 plus span ab contains u1 plus u2 
minus u1, which is u2. 
And similarly, span a contains b, which 
is u3 minus u1. 
So, so u1 plus the span of ab contains u1 
plus u3 minus u1, which is u3. 
So u1 plus big V contains u1, u2, and u3. 
And it's a plane. 
There's only one plane containing those 
three points, so this is it. 
Now, we've written the plane containing 
these three points as this sum: u1 plus 
the span of u2 minus u1, and u3 minus u1. 
There's a nicer way to write this. 
Let's rewrite u1 plus span of u2 minus 
u1, u3 minus u1. 
This is the set of all vectors, u1 plus 
alpha u2 minus u1, plus beta times u3 
minus u1, where alpha and beta range over 
all real numbers. 
We can use the Distributive Law and then 
gather like terms. 
Then, it's the set of all linear 
combinations where the first coefficient 
is 1 minus alpha minus beta, where alpha 
and beta are the other two coefficients. 
So we'll do a substitution. 
We'll replace 1 minus alpha minus beta, 
with another variable gamma, and require 
that gamma plus alpha plus beta equals 1. 
So this is the same set. 
And this is a nicer representation of 
that set. 
So we call this linear combination, where 
the coefficients are required to sum to 
1. 
An affine combination. 
More generally, if you have vectors u1 
through un, a linear combination of those 
vectors is an affine [INAUDIBLE] 
combination if the coefficients sum to 1. 
And the set of all affine combinations of 
u1 through un is called the affine hull 
of those vectors. 
So what using the same argument as 
before, we can see that the affine hull 
of u1, u2, and so on, up to un, can be 
written as u1 plus the span of all these 
vectors, u2 minus u1, u3 minus u1, and so 
on up to un minus u1. 
So this shows that the affine hull of 
vectors is an affine space. 
So we see that we can represent a plane 
as u1 plus a vector space, an affine 
space or the affine hull of some points. 
There's a more familiar way as the 
solution set of an equation, ax plus by 
plus cz equals d. 
Let's rewrite this using vector notation. 
It's the set of all x, y, z, 
such that the dot product of a, b, c with 
x, y, z equals d. 
In general, a point, a line, a plane can 
be written as the solution set of a 
system of linear equations. 
Remember a linear equation is an equation 
involving the dot product with the vector 
variable. 
So here the linear equations are a1 dot x 
equals beta 1 and so on up to am dot x 
equals beta m. 
Well, what about the converse? 
Is the, is the solution set of a linear 
system always an affine space? 
There's a simple counterexample. 
If you take a linear system, That's 
contradictory. 
That has no solutions. 
For example, 1x equals 1, 2x equals 1, 
has no solutions. 
So the solution set in that case is 
empty. 
But we know that because an, a vector 
space always contains the zero vector, 
an affine space, which is u1 plus a 
vector space, always contains at least 
one vector, namely u1. 
So it seems like it breaks down. 
The solution set of a linear system is 
not always an affine space. 
But we've identified the one kind of 
counterexample. 
The one exception. 
And, in fact, there's a theorem that the 
solution set of a linear system is either 
empty or in an affine space, and we'll 
prove that. 
So here's the theorem we're trying to 
prove. 
We start with a concept. 
Each linear system corresponds to another 
linear system in which the right hand 
sides. 
Beta 1 through beta m have all been 
replaced by zeroes . 
And this, a linear equation a dot x 
equals zero, with a zero right hand side 
is called a homogeneous linear equation. 
And a system of homogeneous linear 
equations is called a homogeneous linear 
system. 
So what we've seen is from any linear 
system, we can derive the corresponding 
homogeneous linear system. 
Now we already know that the solution, 
the solution set of a homogeneous of a 
linear system is the vector space. 
Now we use a lemma. 
Let u1 be any solution to some linear 
system. 
Then for any other vector u2, u2 is also 
a solution if and only if u2 minus u1 is 
a solution to the corresponding 
homogeneous linear system. 
Okay. 
Remember, here's a linear system and 
here's the corresponding homogeneous 
linear system. 
Now, let's prove this lemma. 
Let u1 be a solution to a linear system. 
And for any other vector u2, u2 is also a 
solution. 
If and only if u2 minus u1 is a solution 
to the corresponding homogeneous linear 
system. 
So we start with u1, u1 is the solution 
which means that it, it satisfies all 
these equations. 
That is, a1 dot u1 equals beta 1 and so 
on. 
Now, u2 satisfies the same equations if 
and only if the difference between a1 dot 
u2 and a1 dot u1 is zero and so on, up to 
am dot u2 minus am dot u1 to 
zero. 
All those differences have to be zero 
because there, because the right hand 
sides have to match. 
And this is true if and only if a1 dot u2 
minus u1 equals zero and so on, using the 
Distributive Law. 
So we've shown that u2 satisfies those 
equations if and only if u2 minus u1 
satisfies all these equations. 
That completes the proof. 
So here's the lemma. 
Let's see how we can use it to prove the 
theorem. 
We need to show that the solution set of 
a linear system is either empty or affine 
space. 
Okay? 
Let big V be the set of solutions to the 
corresponding homogeneous linear system. 
Now there are two possibilities. 
If the linear system has no solutions, 
then this solution set is empty. 
That's this case. 
Otherwise, it has some solution u1. 
And then, the solution, the set of 
solutions to the linear system is the set 
of u2 such that u2 minus u1 belongs to 
the set of solutions to the homogeneous 
linear system. 
Now we use a substitution. 
We substitute V for u2 minus u1, which 
means u2 equals u1 might plus V. 
So we can rewrite this set in this way. 
And that proves what we wanted to prove. 
That the set of solutions is an affine 
space. 
Now, here's, we've proved more than the 
theorem. 
We've proved that if u1 is a solution to 
a linear system, then the set of all 
solutions to the linear system have this 
form u1 plus V, for all of V in big V, 
where big V is the set of solutions to 
the corresponding homogeneous system. 
Here's some implications of that. 
So long ago, we asked how can we tell if 
a linear system has only one solution? 
Well, this gives us a hint. 
If a linear system has a solution u1, 
then that solution is unique, if and only 
if, a set of solutions to the homogeneous 
linear system consists of just one 
solution. 
We know that the homogeneous linear 
system always contains the zero vector as 
a solution. 
So that must be the only solution to the 
homogeneous linear system for u1 to be 
the unique solution to the original 
linear system. 
We also ask how can we find the number of 
solutions to a linear system over GF(2)? 
Well, now we know the number of solutions 
could be zero, could be the nth the 
solutions set the empty's, empty 
set, otherwise, the number of solutions 
is equal to the number of solutions to 
the corresponding homogeneous linear 
systems. 
[BLANK_AUDIO]. 

