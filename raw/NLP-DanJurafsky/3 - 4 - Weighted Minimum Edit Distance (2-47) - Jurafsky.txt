At a distance can also we waited. Why
would we add waits to the computation of
at a distance. Think about particular
applications. In spell correction it's
obvious that some letters are more likely
to be mistyped than others. While in
biology, because of the constraints of the
subject matter, some kinds of deletions or
insertions are more likely than others.
So, for example in spelling, here's a
confusion matrix for spelling errors, so
if you look at this confusion matrix you
can see that E is very likely to be
confused with A or O and E. So vowels tend
to be confused. But it's very unlikely to
con-, to confuse A and B. So A's are
confused with E's and I's and O's and U's,
and so on. So they're, they're the kinding
of spelling errors people make, have
systematicity to them. So, not just,
confusing vowels with vowels. But also,
the fact of the keyboards means that
you're likely to make errors either using
the homologous finger on the other hand or
using nearby keystrokes. So the
constraints of the domain, in this case
we're talking about spelling, or maybe
we're talking about biology are gonna make
some editive, some edits more likely by
others. So we're going to represent this
by modifying the algorithm slightly to add
weights. So, in Levenshtein Distance we
have the cost of one for insertion and one
for deletion, and two for substitution. In
weighted minimum edit distance, we simply
add a special cost that we have to look
up. So the initialization instead of
adding one for each deletion, we have the
actual cost of deletion; instead of adding
one for each insertion, we add the cost of
each insertion. And so on for the in the
recurrence relation we're gonna add a
special cost. Delete of x of i. How much
does it cost to delete that particular
character? How much does it cost to insert
that character? How much does it cost to
substitute that character? And we're gonna
end up with the, termination condition.
So, we're just gonna add separate little
tables, look up tables, that will tell us
what the deletion, insertion and
substitution costs are. By the way, where
did the name dynamic programming come
from? Here's some quotes from Richard
Bellman's autobiography. Bellman was the
one who invented dynamic programming. And
amusingly, he tells us that he came up
with the, name for dynamic programming
really as a public relations move to make
an algorithm sound exciting. So this is
the, maybe one of the first algorithms
that was, that was named, in a branding
way to make an algorithm sound exciting.
So there's our, in summary, algorithm for
weighted minimum at a distance.
